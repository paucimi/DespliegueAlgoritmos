{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/23 17:19:55 INFO mlflow.tracking.fluent: Experiment with name 'SMS_Spam_Classification' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/775910358339671536', creation_time=1740327595375, experiment_id='775910358339671536', last_update_time=1740327595375, lifecycle_stage='active', name='SMS_Spam_Classification', tags={}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configura el URI de MLflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"SMS_Spam_Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga de Datos y Limpieza Básica\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos columnas (si el dataset viene con 'v1' y 'v2')\n",
    "df = df.rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "df = df[[\"label\", \"text\"]]  # Nos quedamos solo con 'label' y 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Primeras filas del dataset ===\n",
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Primeras filas del dataset ===\")\n",
    "print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Distribución de clases ===\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Distribución de clases ===\")\n",
    "print(df[\"label\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_texto(texto):\n",
    "    texto = texto.lower()                       # minúsculas\n",
    "    texto = re.sub(r\"[^a-zA-Z\\s]\", \"\", texto)   # quitar caracteres especiales\n",
    "    return texto\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Separación de X e y, División en Train/Test\n",
    "X = df[\"text_clean\"]\n",
    "y = df[\"label\"]  # 'ham' o 'spam'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Función para Entrenar y Registrar el Modelo con un valor de n_estimators \n",
    "X = df[\"text_clean\"]\n",
    "y = df[\"label\"]  # 'ham' o 'spam'\n",
    "\n",
    "# 4. División en Entrenamiento y Prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_y_registrar_modelo(n_estimators):\n",
    "    \"\"\"\n",
    "    Crea un pipeline con TfidfVectorizer + RandomForestClassifier,\n",
    "    entrena el modelo con el conjunto de entrenamiento y registra\n",
    "    los resultados en MLflow. Permite comparar distintos n_estimators.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iniciamos un run en MLflow con un nombre que incluya n_estimators\n",
    "    run_name = f\"SMS_Spam_RF_n{n_estimators}\"\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        # 3.1 Creación del Pipeline\n",
    "        pipeline = Pipeline([\n",
    "            (\"tfidf\", TfidfVectorizer(stop_words=\"english\")),\n",
    "            (\"clf\", RandomForestClassifier(\n",
    "                n_estimators=n_estimators,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "        \n",
    "        # 3.2 Entrenamiento\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # 3.3 Predicciones y Métricas\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        precision = report[\"weighted avg\"][\"precision\"]\n",
    "        recall = report[\"weighted avg\"][\"recall\"]\n",
    "        f1 = report[\"weighted avg\"][\"f1-score\"]\n",
    "        \n",
    "        # Mostramos por consola\n",
    "        print(f\"\\n=== Resultados para n_estimators={n_estimators} ===\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        print(\"Matriz de Confusión:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        # 3.4 Registro de Parámetros y Métricas en MLflow\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"random_state\", 42)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # 3.5 Guardar el modelo (pipeline) en MLflow\n",
    "        mlflow.sklearn.log_model(pipeline, f\"modelo_sms_spam_rf_n{n_estimators}\")\n",
    "\n",
    "    print(f\"Entrenamiento y registro completados para n_estimators={n_estimators}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados para n_estimators=50 ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       966\n",
      "        spam       1.00      0.83      0.90       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.91      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[966   0]\n",
      " [ 26 123]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/23 17:50:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SMS_Spam_RF_n50 at: http://127.0.0.1:5000/#/experiments/775910358339671536/runs/52a14585c83248dfa5301977024043d4\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/775910358339671536\n",
      "Entrenamiento y registro completados para n_estimators=50.\n",
      "\n",
      "=== Resultados para n_estimators=100 ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98       966\n",
      "        spam       1.00      0.80      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.90      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[966   0]\n",
      " [ 30 119]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/23 17:50:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SMS_Spam_RF_n100 at: http://127.0.0.1:5000/#/experiments/775910358339671536/runs/9ac34bf146ef48d194a10fb434c02f07\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/775910358339671536\n",
      "Entrenamiento y registro completados para n_estimators=100.\n",
      "\n",
      "=== Resultados para n_estimators=200 ===\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       966\n",
      "        spam       1.00      0.81      0.89       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.99      0.90      0.94      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[966   0]\n",
      " [ 29 120]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/23 17:50:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SMS_Spam_RF_n200 at: http://127.0.0.1:5000/#/experiments/775910358339671536/runs/55ddd91c22404aff92f2c8f16726b5ae\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/775910358339671536\n",
      "Entrenamiento y registro completados para n_estimators=200.\n",
      "\n",
      "¡Todas las ejecuciones se han completado!\n"
     ]
    }
   ],
   "source": [
    "# 4. Llamar a la Función con Distintos Valores de n_estimators\n",
    "valores_n_estimators = [50, 100, 200]\n",
    "\n",
    "for n in valores_n_estimators:\n",
    "    entrenar_y_registrar_modelo(n)\n",
    "\n",
    "print(\"\\n¡Todas las ejecuciones se han completado!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd14-despliegue-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
